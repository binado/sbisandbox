{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SBI Sandbox","text":"<p>Welcome to SBI Sandbox. This project is intended as an introduction to Simulation-Based Inference (SBI).</p>"},{"location":"#explore","title":"Explore","text":"<p>Feel free to</p> <ul> <li>Learn more about SBI</li> <li>Go through our glossary for a quick overview of the most important concepts and methods</li> <li>Replay our tutorial notebooks for a hands-on introduction</li> <li>Read the installation instructions to use the package locally</li> <li>Dive into more resources related to SBI</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This project uses the <code>sbi</code> package and was inspired by the <code>sbibm</code> benchmark suite. See their corresponding links and references in the resources page.</p>"},{"location":"about/","title":"About Simulation-Based Inference","text":"<p>The problem of inference is ubiquitous in modern science. In the past decades, many statistical tools have seen their use consolidated across different scientific fields, either through frequentist or Bayesian approaches.</p> <p>In parallel, the design of more powerful and more efficient computing hardware has allowed for the design of high-fidelity simulations of physical systems with increasing complexity, allowing for the generation of synthetic data from them. However, performing inference from these simulators still remains challenging. In these contexts, the likelihood function is not explicitly calculated, and is instead implicitly defined by the data-generating process implemented by the simulator. The problem of performing inference with these systems has thus been named likelihood-free inference or simulation-based inference (hereafter SBI).</p> <p>In the past few years, the development of more sophisticated Machine Learning techniques, in particular deep neural networks, and the production of specialized hardware for training has given new momentum to the field of SBI. For a high-level overview of the impact of these trends on the emergence of new methods, we refer the reader to this review paper by (Cranmer et al, 2019).</p> <p>For more information on applications of SBI in scientific problems, see our resources section.</p>"},{"location":"about/#references","title":"References","text":"<p>[1]: Cranmer, Kyle, Johann Brehmer, and Gilles Louppe. \"The frontier of simulation-based inference.\" Proceedings of the National Academy of Sciences 117.48 (2020): 30055-30062.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#running_the_tutorial_notebooks","title":"Running the tutorial notebooks","text":"<p>You can run the tutorial notebooks directly in Google Colab. To correctly install all required packages, make sure to run the command</p> <pre><code>!pip install git+https://github.com/binado/sbisandbox.git\n</code></pre> <p>in an empty cell in the beginning of the notebook.</p>"},{"location":"install/#local_installation","title":"Local installation","text":"<p>Clone the repo with</p> <pre><code>git clone https://github.com/binado/sbisandbox.git\n</code></pre> <p>and run</p> <pre><code>pip install .\n</code></pre> <p>If possible, we recommend creating a new <code>conda</code> environment first:</p> <pre><code>conda create -n sbisandbox python=3.10 &amp;&amp; conda activate sbisandbox\n</code></pre>"},{"location":"resources/","title":"Resources","text":"<p>We list below valuable resources related to SBI that we found during our research.</p>"},{"location":"resources/#compilations","title":"Compilations","text":"<p>For more complete lists of related papers and sofware, check out</p> <ul> <li>simulation-based-inference.org, which aggregates hundreds of scientific papers using Simulation-based Inference in different fields.</li> <li> Awesome Neural SBI, a Github repsitory containing a curated list of methodological and applied papers, software packages, and tutorials.</li> </ul>"},{"location":"resources/#software_packages","title":"Software packages","text":"<ul> <li> sbi: A user-friendly Python package implementing the most common SBI algorithms.</li> <li> sbibm: A Simulation-Based Inference Benchmark comparing SBI algorithms' performances accross different tasks and metrics.</li> </ul>"},{"location":"resources/#references","title":"References","text":"<p>[1]: Tejero-Cantero, Alvaro, et al. \"SBI--A toolkit for simulation-based inference.\" arXiv preprint arXiv:2007.09114 (2020).</p> <p>[2]: Lueckmann, Jan-Matthis, et al. \"Benchmarking simulation-based inference.\" International conference on artificial intelligence and statistics. PMLR, 2021.</p>"},{"location":"glossary/","title":"Glossary","text":"<ul> <li>Amortized x sequential algorithms</li> <li>Neural Likelihood Estimation</li> <li>Neural Posterior Estimation</li> <li>Neural Ratio Estimation</li> <li>Normalizing flows</li> <li>Simulator</li> </ul>"},{"location":"glossary/amortization/","title":"Amortized x sequential algorithms","text":""},{"location":"glossary/amortization/#amortization","title":"Amortization","text":"<p>One advantage of neural SBI algorithms is that the neural network is an amortized estimator of the posterior. That is, it learns \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\) for any value of $\\boldsymbol{x}, in contrast with traditional sampling methods, were the inference pipeline must be rerun with the new data.</p> <p>Amortization also makes it more viable to run expected coverage tests, which are a useful diagnostic tool to identify overconfident/underconfident estimators (see [2]).</p>"},{"location":"glossary/amortization/#sequential_variants","title":"Sequential variants","text":"<p>There are may be situations in which we do want to learn the posterior for only a particular observation \\(\\boldsymbol{x}_0\\). In that case, there are strategies to employ to reduce the simulation budget required for learning the posterior in the neighbourhood of \\(\\boldsymbol{x}_0\\).</p> <p>The main idea is to construct a proposal distribution \\(\\tilde{p}(\\boldsymbol{\\theta})\\), not necessarily the prior \\(p(\\boldsymbol{\\theta})\\), that generates samples whose simulator output is close to \\(\\boldsymbol{x}_0\\). In practice, the training of the neural network is performed over several rounds; the outpout estimator at the end of each round being chosen as the proposal distribution for the next.</p>"},{"location":"glossary/amortization/#references","title":"References","text":"<p>[1]: Papamakarios, George, David Sterratt, and Iain Murray. \"Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows.\" The 22nd international conference on artificial intelligence and statistics. PMLR, 2019.</p> <p>[2]: Hermans, Joeri, et al. \"A trust crisis in simulation-based inference? your posterior approximations can be unfaithful.\" arXiv preprint arXiv:2110.06581 (2021).</p>"},{"location":"glossary/nflow/","title":"Normalizing flows","text":""},{"location":"glossary/nflow/#introduction","title":"Introduction","text":"<p>In a nutshell, a normalizing flow is based on the idea of a set of invertible and differentible transformations between two distributions. Let's say that \\(x\\) follows a base distribution with density \\(p(x)\\), and we consider the bijection \\(f: x \\to z\\). The transformed variable \\(z\\) will follow a distribution with density</p> \\[ \\begin{aligned} p'(z) &amp;= p(f^{-1}(z)) \\left| \\frac{\\partial f^{-1}}{\\partial z} \\right|\\\\ &amp;= p(f^{-1}(z)) \\left| \\frac{\\partial f}{\\partial x} \\right|^{-1} \\end{aligned} \\] <p>The above relation is easily generalized to the multidimensional case by replacing the partial derivative with the determinant of the jacobian of the transformation \\(\\text{det} \\frac{\\partial f}{\\partial x_i}\\).</p> <p>These transformation can be arbitrarily composed, e.g.</p> \\[ f = f_n \\circ \\ldots f_2 \\circ f_1,\\] <p>which amounts to multiplying the jacobian determinants,</p> \\[\\text{det }\\frac{\\partial f}{\\partial \\boldsymbol{x}_n} = \\prod_{i=1}^n \\text{det } \\frac{\\partial f_i}{\\partial \\boldsymbol{x}_i}.\\] <p>In the context of inference, a generative model can be generally viewed as a (possibly non-linear) transformation from a simple distribution (e.g. a prior) to a more complex distribution (e.g. the posterior). The idea of the method is that a well-parameterized composition of normalizing flows will approximate the inverse transformation.</p> <p>Typically, the normalizing flows can be represented by a neural network architecture, whose input parameters \\(\\phi\\) are the subject to an optimization to maximize a suitable loss function, for instance the log-posterior, or a suitable distance metric in the case of variational inference.</p>"},{"location":"glossary/nflow/#more_resources","title":"More resources","text":"<p>For a more formal discussion on the subject, we refer the reader to this review paper.</p>"},{"location":"glossary/nflow/#references","title":"References","text":"<p>[1]: Kobyzev, Ivan, Simon JD Prince, and Marcus A. Brubaker. \"Normalizing flows: An introduction and review of current methods.\" IEEE transactions on pattern analysis and machine intelligence 43.11 (2020): 3964-3979.</p>"},{"location":"glossary/nle/","title":"Neural Likelihood Estimation (NLE)","text":""},{"location":"glossary/nle/#introduction","title":"Introduction","text":"<p>Neural Posterior Estimation (NPE) consists of training a neural density estimator with a simulated dataset to directly approximate the likelihood \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\).</p> <p>The estimator is trained to minimize the loss function</p> \\[     \\mathcal{L}(\\boldsymbol{\\phi}) = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right], \\] <p>where \\(\\boldsymbol{\\phi}\\) is the parameter vector of the neural network. The loss function attains a minimum at \\(q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) = p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\). Indeed, by writing it explicity,</p> \\[     \\mathcal{L} = -\\iint d\\boldsymbol{\\theta} d\\boldsymbol{x}  p(\\boldsymbol{\\theta}) p(\\boldsymbol{x} | \\boldsymbol{\\theta}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}), \\] <p>one can apply Bayes' theorem and commute the integrals to write $$ \\begin{split}     \\mathcal{L} &amp;= -\\int d\\boldsymbol{x} p(\\boldsymbol{x}) \\int d\\boldsymbol{\\theta} p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\     &amp;=D_{KL}\\left[q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\parallel p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right] + \\rm{const}, \\end{split} $$</p> <p>where the first term is recognized to be the conditional relative entropy between \\(q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x})\\) and the true posterior distribution \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\), which is zero if and only if the two measures are equal almost everywhere, and positive otherwise. The additional constant term does not depend on  \\(q_{\\boldsymbol{\\phi}}\\) and equals</p> \\[     \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right]. \\] <p>A common implementation of the density estimator is a normalizing flow.</p>"},{"location":"glossary/nle/#references","title":"References","text":"<p>[1]: Papamakarios, George, David Sterratt, and Iain Murray. \"Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows.\" The 22nd international conference on artificial intelligence and statistics. PMLR, 2019.</p>"},{"location":"glossary/npe/","title":"Neural Posterior Estimation (NPE)","text":""},{"location":"glossary/npe/#introduction","title":"Introduction","text":"<p>Neural Posterior Estimation (NPE) consists of training a neural density estimator with a simulated dataset to directly approximate the posterior \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\).</p> <p>The estimator is trained to minimize the loss function</p> \\[     \\mathcal{L}(\\boldsymbol{\\phi}) = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right], \\] <p>where \\(\\boldsymbol{\\phi}\\) is the parameter vector of the neural network. The loss function attains a minimum at \\(q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) = p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\). Indeed, by writing it explicity,</p> \\[     \\mathcal{L} = -\\iint d\\boldsymbol{\\theta} d\\boldsymbol{x}  p(\\boldsymbol{\\theta}) p(\\boldsymbol{x} | \\boldsymbol{\\theta}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}), \\] <p>one can apply Bayes' theorem and commute the integrals to write $$ \\begin{split}     \\mathcal{L} &amp;= -\\int d\\boldsymbol{x} p(\\boldsymbol{x}) \\int d\\boldsymbol{\\theta} p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\     &amp;=D_{KL}\\left[q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\parallel p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right] + \\rm{const}, \\end{split} $$</p> <p>where the first term is recognized to be the conditional relative entropy between \\(q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x})\\) and the true posterior distribution \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\), which is zero if and only if the two measures are equal almost everywhere, and positive otherwise. The additional constant term does not depend on  \\(q_{\\boldsymbol{\\phi}}\\) and equals</p> \\[     \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right]. \\] <p>A common implementation of the density estimator is a normalizing flow.</p>"},{"location":"glossary/npe/#comparison_with_other_methods","title":"Comparison with other methods","text":"<p>One advantage of this approach is that one can obtain samples from the posterior directly from the density estimator itself, contrary to NLE or NRE.</p>"},{"location":"glossary/npe/#references","title":"References","text":"<p>[1]: Papamakarios, George, and Iain Murray. \"Fast \u03b5-free inference of simulation models with bayesian conditional density estimation.\" Advances in neural information processing systems 29 (2016).</p> <p>[2]: Lueckmann, Jan-Matthis, et al. \"Flexible statistical inference for mechanistic models of neural dynamics.\" Advances in neural information processing systems 30 (2017).</p> <p>[3]: Greenberg, David, Marcel Nonnenmacher, and Jakob Macke. \"Automatic posterior transformation for likelihood-free inference.\" International Conference on Machine Learning. PMLR, 2019.</p> <p>[4]: Deistler, Michael, Pedro J. Goncalves, and Jakob H. Macke. \"Truncated proposals for scalable and hassle-free simulation-based inference.\" Advances in Neural Information Processing Systems 35 (2022): 23135-23149.</p>"},{"location":"glossary/nre/","title":"Neural Ratio Estimation (NRE)","text":""},{"location":"glossary/nre/#introduction","title":"Introduction","text":"<p>As we have seen, the output of prior + simulator is the array of pairs \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i)\\) is drawn from the joint distribution</p> \\[     (\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i) \\sim p(\\boldsymbol{x}, \\boldsymbol{\\theta}) = p(\\boldsymbol{x} | \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) \\] <p>We now consider the shuffled pairs \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_j)\\), where \\(\\boldsymbol{x}_i\\) is the output of the forward-modeled input \\(\\boldsymbol{\\theta}_i, \\, i \\neq j\\). These pairs are sampled from the product distribution</p> \\[     (\\boldsymbol{x}_i, \\boldsymbol{\\theta}_j) \\sim p(\\boldsymbol{x}) p(\\boldsymbol{\\theta}) \\] <p>The idea of NRE is to train a classifier to learn the ratio</p> \\[     r(\\boldsymbol{x}, \\boldsymbol{\\theta}) \\equiv \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})p(\\boldsymbol{\\theta})} = \\frac{p(\\boldsymbol{x} | \\boldsymbol{\\theta})}{p(\\boldsymbol{x})}, \\] <p>which is equal to the likelihood-to-evidence ratio. The application of Bayes' theorem makes the connection between \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) and the Bayesian inverse problem:</p> \\[     r(\\boldsymbol{x}, \\boldsymbol{\\theta}) = \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})} = \\frac{p(\\boldsymbol{\\theta} | \\boldsymbol{x})}{p(\\boldsymbol{\\theta})}. \\] <p>In other words, \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) equals the posterior-to-prior ratio. Therefore, one can get samples from the posterior distribution of \\(\\boldsymbol{\\theta}\\) from the approximate knowledge of \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) and prior samples from \\(\\boldsymbol{\\theta}\\).</p> <p>More specifically, the binary classifier \\(d_{\\boldsymbol{\\phi}} (\\boldsymbol{x}, \\boldsymbol{\\theta})\\) with learnable parameters \\(\\boldsymbol{\\phi}\\) is trained to distinguish the \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i)\\) pairs sampled from the joint distribution from their shuffled counterparts. We label pairs with a variable \\(y\\), such that \\(y=1\\) refers to joint pairs, and \\(y=0\\) to shuffled pairs. The classifier is trained to approximate</p> \\[\\begin{equation*} \\begin{split}     d_{\\boldsymbol{\\phi}} (\\boldsymbol{x}, \\boldsymbol{\\theta}) &amp;\\approx p(y=1 | \\boldsymbol{x}, \\boldsymbol{\\theta})\\\\     &amp;= \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 1) p(y = 1)}{p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 0) p(y = 0) + p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 1) p(y = 1)}\\\\     &amp;= \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})\\boldsymbol{\\theta} + p(\\boldsymbol{x}, \\boldsymbol{\\theta})}\\\\     &amp;= \\frac{r(\\boldsymbol{x}, \\boldsymbol{\\theta)}}{1 + r(\\boldsymbol{x}, \\boldsymbol{\\theta)}}, \\end{split} \\end{equation*}\\] <p>where we used \\(p(y=0)=p(y=1)=0.5\\).</p> <p>The classifier learns the parameters \\(\\boldsymbol{\\phi}\\) by minimizing the binary-cross entropy, defined as</p> \\[     L(d_{\\boldsymbol{\\phi}}) = - \\int d\\boldsymbol{\\theta} \\int d\\boldsymbol{x} p(\\boldsymbol{x}, \\boldsymbol{\\theta})\\log d_{\\boldsymbol{\\phi}}(\\boldsymbol{x}, \\boldsymbol{\\theta}) - p(\\boldsymbol{x})\\boldsymbol{\\theta}\\log(1-d_{\\boldsymbol{\\phi}}(\\boldsymbol{x}, \\boldsymbol{\\theta})) \\]"},{"location":"glossary/nre/#references","title":"References","text":"<p>[1]: Hermans, Joeri, Volodimir Begy, and Gilles Louppe. \"Likelihood-free mcmc with amortized approximate ratio estimators.\" International conference on machine learning. PMLR, 2020.</p> <p>[2]: Miller, Benjamin K., et al. \"Truncated marginal neural ratio estimation.\" Advances in Neural Information Processing Systems 34 (2021): 129-143.</p> <p>[3]: Anau Montel, Noemi, James Alvey, and Christoph Weniger. \"Scalable inference with autoregressive neural ratio estimation.\" Monthly Notices of the Royal Astronomical Society 530.4 (2024): 4107-4124.</p>"},{"location":"glossary/simulator/","title":"Simulator","text":""},{"location":"glossary/simulator/#introduction","title":"Introduction","text":"<p>The simulator is the general term for the function mapping the model parameters, \\(\\boldsymbol{\\theta}\\), to the observed data, \\(\\boldsymbol{x}\\). It implicitly defines a likelihood function \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\), in the sense that it returns samples \\(\\boldsymbol{x}\\) which follow a distribution whose density is \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\). Therefore, once a prior on \\(\\boldsymbol{\\theta}\\) is specified, we have all the necessary ingredients to perform Bayesian inference.</p>"},{"location":"glossary/simulator/#examples","title":"Examples","text":""},{"location":"glossary/simulator/#gaussian_linear","title":"Gaussian linear","text":"<p>Consider a simple model where the output data are the parameters plus some gaussian noise:</p> \\[ x = \\theta + \\sigma \\varepsilon,\\] <p>where \\(\\varepsilon \\sim \\mathcal{N}(0, 1)\\). This corresponds to the likelihood function</p> \\[ \\log p(x | \\theta) \\propto -\\frac{1}{2} \\left(\\frac{x - \\theta}{\\sigma} \\right)^2\\]"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#available_tutorials","title":"Available tutorials","text":"<ul> <li>Introduction</li> </ul>"},{"location":"tutorials/#running_the_tutorial_notebooks","title":"Running the tutorial notebooks","text":"<p>You can run the tutorial notebooks directly in Google Colab. To correctly install all required packages, make sure to run the command</p> <pre><code>!pip install git+https://github.com/binado/sbisandbox.git\n</code></pre> <p>in an empty cell in the beginning of the notebook.</p>"},{"location":"tutorials/introduction/","title":"Introduction","text":""},{"location":"tutorials/introduction/#sbi_experiments_an_introduction","title":"SBI experiments: an introduction","text":"<p>In this notebook, we will introduce three major Simulation-based inference algorithms powered by neural networks. We will use them to perform Bayesian inference on the toy example of estimating the centre of a multivariate normal distribution.</p> <p>All methods used here will be implemented on top of Pytorch, a popular Python package used for performing GPU-accelerated computations with tensors (a.k.a multi-dimensional arrays) as well as for building neural network models.</p> <p>We will use the SBI algorithms' implementations from the <code>sbi</code> package, which uses Pytorch under the hood.</p>"},{"location":"tutorials/introduction/#the_model","title":"The model","text":"<p>We will choose a model where both parameters and data are sampled from a multivariate normal distribution.</p> <p>The parameters \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^n\\) are sampled from</p> \\[ \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mu=\\boldsymbol{0}_n, \\Sigma_1=\\sigma \\boldsymbol{I}_n),\\] <p>where \\(\\sigma &gt; 0\\), \\(\\boldsymbol{I}_n\\) is the n x n identity matrix and \\(\\boldsymbol{0}_n = \\begin{pmatrix} 0 &amp; \\ldots &amp; 0 \\end{pmatrix}^T \\in \\mathbb{R}^n\\). The data \\(\\boldsymbol{x} \\in \\mathbb{R}^n\\) are generated as follows:</p> \\[ \\boldsymbol{x} \\sim \\mathcal{N}(\\mu=\\boldsymbol{\\theta}, \\Sigma_2=\\sigma \\boldsymbol{I}_n) \\] <p>We hereafter fix \\(\\sigma = 0.01\\).</p>"},{"location":"tutorials/introduction/#the_analytical_posterior","title":"The analytical posterior","text":"<p>The posterior distribution can be calculated analytically for this case. Ignoring normalization factors and terms independent of \\(\\boldsymbol{\\theta}\\), we can write</p> \\[\\begin{align*} \\log p(\\boldsymbol{\\theta} | \\boldsymbol{x}) &amp;\\propto -\\frac{1}{2}(\\boldsymbol{x} - \\boldsymbol{\\theta})^T \\Sigma^{-1}_2 (\\boldsymbol{x} -\\boldsymbol{\\theta}) - \\frac{1}{2}\\boldsymbol{\\theta}^T \\Sigma^{-1}_1 \\boldsymbol{\\theta}\\\\ &amp;\\propto \\boldsymbol{\\theta}^T \\Sigma^{-1}_2 \\boldsymbol{x} - \\frac{1}{2}\\boldsymbol{\\theta}^T(\\Sigma^{-1}_1 + \\Sigma^{-1}_2)\\boldsymbol {\\theta}, \\end{align*}\\] <p>which, after completing the square, is found to follow a multivariate normal \\(\\mathcal{N}(\\mu, \\Sigma_T)\\) distribution of mean and convariance matrix</p> \\[ \\Sigma_T = (\\Sigma_1^{-1} + \\Sigma_2^{-1})^{-1} = \\frac{\\sigma}{2} \\boldsymbol{I}_n\\] \\[ \\mu = \\Sigma_T \\Sigma^{-1}_2 \\boldsymbol{x} = \\frac{\\boldsymbol{x}}{2},\\] <p>the last equality being valid when \\(\\Sigma_1 = \\Sigma_2\\).</p> <pre><code># Uncomment the line below to install the package in Google colab\n#!pip install git+https://github.com/binado/sbisandbox.git\n</code></pre> <pre><code>import sys\n\nsys.path.append(\"..\")\n\nimport torch\nfrom torch import Tensor\nimport arviz as az\nfrom sbi import analysis as analysis\nfrom sbi import utils as utils\nfrom sbi.inference import simulate_for_sbi\nfrom sbi.utils.user_input_checks import (\n    check_sbi_inputs,\n    process_prior,\n    process_simulator,\n)\n\n%config InlineBackend.figure_format = 'retina'\naz.style.use(\"arviz-whitegrid\")\n</code></pre> <pre><code>/Users/bernardoveronese/miniconda3/envs/sbibench/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \nFound Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\nthe same time. Both libraries are known to be incompatible and this\ncan cause random crashes or deadlocks on Linux when loaded in the\nsame Python program.\nUsing threadpoolctl may cause crashes or deadlocks. For more\ninformation and possible workarounds, please see\n    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n\n  warnings.warn(msg, RuntimeWarning)\n</code></pre>"},{"location":"tutorials/introduction/#implementing_the_model","title":"Implementing the model","text":"<p>The main ingredient for SBI is the simulator, which serves as a forward model from input parameters \\(\\boldsymbol{\\theta}\\) to data samples \\(\\boldsymbol{x}\\). If the input are drawn from a proposal distribution \\(\\boldsymbol{\\theta}\\), the simulator implicitly defines the mapping \\(\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\).</p> <p>We implement the gaussian model in the two functions below. Multi-dimensional arrays, or tensors, are represented in Pytorch with the <code>torch.tensor</code> object, which is very similar to Numpy's <code>ndarray</code>, while also having support for running on GPUs.</p> <pre><code>ndim = 5  # You can change the number of dimensions\nseed = 1998\ntorch.manual_seed(seed)\n</code></pre> <pre><code>&lt;torch._C.Generator at 0x11254c210&gt;\n</code></pre> <pre><code>from torch.distributions import Distribution, MultivariateNormal\n\ncov = 0.01\ntheta_loc = torch.zeros(ndim)\ntheta_precision_matrix = torch.eye(ndim) / cov\nx_precision_matrix = torch.eye(ndim) / cov\n\n\ndef get_prior() -&gt; Distribution:\n    # Return the prior distribution\n    return MultivariateNormal(loc=theta_loc, precision_matrix=theta_precision_matrix)\n\n\ndef gaussian_linear_simulator(theta: Tensor) -&gt; Tensor:\n    # theta is a tensor of shape (num_samples, ndim)\n    return MultivariateNormal(loc=theta, precision_matrix=x_precision_matrix).sample()\n\n\ndef get_true_distribution(x: Tensor) -&gt; MultivariateNormal:\n    precision_matrix = theta_precision_matrix + x_precision_matrix\n    loc = torch.linalg.solve(precision_matrix, x_precision_matrix @ x.squeeze())\n    return MultivariateNormal(loc=loc, precision_matrix=precision_matrix)\n\n\ndef log_prob(theta: Tensor, x: Tensor) -&gt; Tensor:\n    dist = get_true_distribution(x)\n    return dist.log_prob(theta)\n\n\ndef get_true_posterior_samples(num_samples: int, x: Tensor) -&gt; Tensor:\n    # Return samples from the analytical posterior\n    dist = get_true_distribution(x)\n    return dist.expand((num_samples,)).sample()\n</code></pre> <p>Let us define some utility functions which are going to be convenient for generating plots based on our samples:</p> <pre><code>def get_labels_for_var(var: str, n: int):\n    return list(map(lambda i: f\"${var}_{{{i}}}$\", range(1, n + 1)))\n\n\ndef tensor_to_dataset(labels, tensor):\n    return dict(zip(labels, [tensor[..., i] for i in range(tensor.shape[-1])]))\n</code></pre> <p>In the cell below, we use the <code>process_prior</code> and <code>process_simulator</code> helper methods from <code>sbi</code> to convert the prior and simulator into functions whith the appropriate return types for the package. Alternatively, you may use the helper method <code>sbisandbox.utils.validate_model</code>.</p> <pre><code>prior = get_prior()\n# Check prior, return PyTorch prior.\nprior, num_parameters, prior_returns_numpy = process_prior(prior)\n\n# Check simulator, returns PyTorch simulator able to simulate batches.\nsimulator = process_simulator(gaussian_linear_simulator, prior, prior_returns_numpy)\n\n# Consistency check after making ready for sbi.\ncheck_sbi_inputs(simulator, prior)\n</code></pre>"},{"location":"tutorials/introduction/#visualizing_the_data","title":"Visualizing the data","text":"<p>Let us use the <code>simulate_for_sbi</code> helper method to generate samples of \\(\\theta\\) and \\(x\\).</p> <pre><code>num_simulations = 1000\ntheta, x = simulate_for_sbi(simulator, proposal=prior, num_simulations=num_simulations)\ntheta.shape, x.shape\n</code></pre> <pre><code>Running 1000 simulations.:   0%|          | 0/1000 [00:00&lt;?, ?it/s]\n\n\n\n\n\n(torch.Size([1000, 5]), torch.Size([1000, 5]))\n</code></pre> <p>Density plots for our parameter samples:</p> <pre><code>theta_labels = get_labels_for_var(\"\\\\theta\", ndim)\ntheta_dataset = tensor_to_dataset(theta_labels, theta)\n\nplot_kwargs = dict(shade=0.8, show=True)  # grid=(5, 2), figsize=(12, 20), show=True)\naz.plot_density(theta_dataset, var_names=theta_labels, **plot_kwargs)\n</code></pre> <p></p> <pre><code>array([[&lt;Axes: title={'center': '$\\\\theta_{1}$'}&gt;,\n        &lt;Axes: title={'center': '$\\\\theta_{2}$'}&gt;,\n        &lt;Axes: title={'center': '$\\\\theta_{3}$'}&gt;],\n       [&lt;Axes: title={'center': '$\\\\theta_{4}$'}&gt;,\n        &lt;Axes: title={'center': '$\\\\theta_{5}$'}&gt;, &lt;Axes: &gt;]],\n      dtype=object)\n</code></pre> <p>Density plots for the generated data:</p> <pre><code>x_labels = get_labels_for_var(\"x\", ndim)\nx_dataset = tensor_to_dataset(x_labels, x)\n\naz.plot_density(x_dataset, var_names=x_labels, **plot_kwargs)\n</code></pre> <p></p> <pre><code>array([[&lt;Axes: title={'center': '$x_{1}$'}&gt;,\n        &lt;Axes: title={'center': '$x_{2}$'}&gt;,\n        &lt;Axes: title={'center': '$x_{3}$'}&gt;],\n       [&lt;Axes: title={'center': '$x_{4}$'}&gt;,\n        &lt;Axes: title={'center': '$x_{5}$'}&gt;, &lt;Axes: &gt;]], dtype=object)\n</code></pre> <p>The output of prior + simulator is the set of samples</p> \\[\\{(\\boldsymbol{\\theta}_i, \\boldsymbol{x}_i)\\},\\] <p>for \\(i=1, \\ldots, N_{sim}\\). This will be the data used for the training and validation of the neural network, which is are both taken care of by <code>sbi</code>. Higher simulation budgets \\(N_{sim}\\) increase the training time of the network, but normally yield better approximations for the true posterior - although the scaling is not expected to be linear.</p>"},{"location":"tutorials/introduction/#simulator_sanity-checks","title":"Simulator sanity-checks","text":"<p>Let us fix a fiducial \\(\\boldsymbol{\\theta}_0\\) and use it as input to our simulator many times to get independent samples of \\(\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta}_0)\\), and see if we recover the expected normal distribution centered around \\(\\boldsymbol{\\theta}_0\\):</p> <pre><code>theta_0 = torch.zeros(1000, ndim)\nx_of_theta_0 = simulator(theta_0)\nx_labels = get_labels_for_var(\"x\", ndim)\n\n\ndef plot_corner(labels, samples, truths):\n    dataset = tensor_to_dataset(labels, samples)\n    reference_values = tensor_to_dataset(labels, truths)\n    with az.rc_context({\"plot.max_subplots\": ndim**2 + 1}):\n        _ = az.plot_pair(\n            dataset,\n            var_names=labels,\n            marginals=True,\n            reference_values=reference_values,\n            reference_values_kwargs={\"ls\": \"dotted\", \"markersize\": 20, \"color\": \"red\"},\n        )\n\n\nplot_corner(x_labels, x_of_theta_0, theta_0)\n</code></pre> <p></p> <p>Fixing nominal values:</p> <pre><code>%precision 3\nfiducial_theta, fiducial_x = simulate_for_sbi(simulator, prior, 1)\n{\n    \"Fiducial theta\": fiducial_theta.squeeze().tolist(),\n    \"Data point\": fiducial_x.squeeze().tolist(),\n}\n</code></pre> <pre><code>{'Fiducial theta': [0.122, -0.130, 0.202, -0.004, -0.035],\n 'Data point': [-0.036, -0.246, 0.333, -0.174, -0.120]}\n</code></pre>"},{"location":"tutorials/introduction/#performing_simulation-based_inference","title":"Performing Simulation-based inference","text":""},{"location":"tutorials/introduction/#neural_posterior_estimation_npe","title":"Neural Posterior Estimation (NPE)","text":"<p>Neural Posterior Estimation (NPE) consists of training a neural density estimator with a simulated dataset to directly approximate the posterior \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\). One advantage of this approach is that one can directly sample from the amortized approximation of the posterior, without having to perform extra MCMC steps.</p> <p>The estimator is trained to minimize the loss function</p> \\[     \\mathcal{L}(\\boldsymbol{\\phi}) = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right], \\] <p>where \\(\\boldsymbol{\\phi}\\) is the parameter vector of the neural network. The loss function attains a minimum at \\(q_{\\boldsymbol{\\phi}} (\\boldsymbol{\\theta} | \\boldsymbol{x}) = p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\). Indeed, by writing it explicity,</p> \\[     \\mathcal{L} = -\\iint d\\boldsymbol{\\theta} d\\boldsymbol{x}  p(\\boldsymbol{\\theta}) p(\\boldsymbol{x} | \\boldsymbol{\\theta}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}), \\] <p>one can apply Bayes' theorem and commute the integrals to write $$ \\begin{split}     \\mathcal{L} &amp;= -\\int d\\boldsymbol{x} p(\\boldsymbol{x}) \\int d\\boldsymbol{\\theta} p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\log q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\     &amp;=D_{KL}\\left[q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\parallel p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right] + \\rm{const}, \\end{split} $$ where the first term is recognized to be the conditional relative entropy between \\(q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x})\\) and the true posterior distribution \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\), which is zero if and only if the two measures are equal almost everywhere, and positive otherwise. The additional constant term does not depend on  \\(q_{\\boldsymbol{\\phi}}\\) and equals</p> \\[     \\mathbb{E}_{\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta})} \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} | \\boldsymbol{\\theta})} \\left[-\\log p(\\boldsymbol{\\theta} | \\boldsymbol{x}) \\right]. \\] <p>A common implementation of the estimator \\(q_{\\boldsymbol{\\phi}}(\\boldsymbol{\\theta} | \\boldsymbol{x})\\) is with a normalizing flow. In a nutshell, a normalizing flow is based on the idea of a set of invertible and differentible transformations between two distributions. If we consider our generative model as a series of transformations from a simple distribution (e.g. a prior) to a complex distribution (e.g. the posterior), the normalizing flow will attempt to learn the inverse transformations. For a more formal discussion on the subject, we refer the reader to this review paper.</p> <pre><code>from sbi.inference import SNPE\n\ninference = SNPE(prior=prior)\ninference.append_simulations(theta, x)\n</code></pre> <pre><code>&lt;sbi.inference.snpe.snpe_c.SNPE_C at 0x157be57e0&gt;\n</code></pre> <p>We train the neural network with the <code>train</code> method. A number of arguments can be specified to tune the training hyperparameters (see the docs), but we will stick to their default values here.</p> <pre><code>%%time\ndensity_estimator = inference.train()\n</code></pre> <pre><code> Neural network successfully converged after 56 epochs.CPU times: user 23.8 s, sys: 874 ms, total: 24.6 s\nWall time: 15.7 s\n</code></pre> <p>The output of the training is the density estimator, which we can use to build the posterior:</p> <pre><code>posterior = inference.build_posterior(density_estimator=density_estimator)\n</code></pre> <p>Now that we have built an estimator for the posterior probability \\(p(\\boldsymbol{\\theta} | \\boldsymbol{x})\\), we draw a fiducial pair \\((\\boldsymbol{\\theta}_f, \\boldsymbol{x}_f)\\) to serve as our observed data. In the last line, we use the <code>.sample</code> method to sample from the approximate posterior density.</p> <pre><code>%%time\nnum_samples = 1000\nsamples_from_npe = posterior.sample((num_samples,), x=fiducial_x)\n</code></pre> <pre><code>Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00&lt;?, ?it/s]\n\n\nCPU times: user 120 ms, sys: 9.42 ms, total: 129 ms\nWall time: 127 ms\n</code></pre> <pre><code>plot_corner(theta_labels, samples_from_npe, fiducial_theta.squeeze())\n</code></pre> <p></p>"},{"location":"tutorials/introduction/#neural_likelihood_estimation_nle","title":"Neural Likelihood Estimation (NLE)","text":"<p>Neural Likelihood Estimation (NLE) shares the same philosophy of NPE, but tries to learn the likelihood \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\) instead of the posterior. Let us redo the calculations with this method.</p> <pre><code>from sbi.inference import SNLE\n\ninference = SNLE(prior=prior)\ninference.append_simulations(theta, x)\n</code></pre> <pre><code>&lt;sbi.inference.snle.snle_a.SNLE_A at 0x15b19d690&gt;\n</code></pre> <pre><code>%%time\ndensity_estimator = inference.train()\n</code></pre> <pre><code> Neural network successfully converged after 35 epochs.CPU times: user 14.1 s, sys: 278 ms, total: 14.4 s\nWall time: 8.16 s\n</code></pre> <p>The differences between NPE and NLE start to show once we have trained the neural network and want to build the posterior. The density estimator approximates the likelihood \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta})\\), therefore we need an additional computational step to obtain samples from the posterior \\(p(\\boldsymbol{x} | \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})\\). This may be achieved with standard sampling methods, such as MCMC, rejection sampling, importance sampling, etc. In the context of our toy model, the procedure may seem redundant, as we know the analytical form of the likelihood. However, as we consider more complex models, for which the form of the likelihood is intractable, the SBI approach allows us to relax any analytical approximations (e.g. gaussian distribution) and let the neural network itself learn the non-linear mapping between \\(\\boldsymbol{\\theta}\\) and \\(\\boldsymbol{x}\\).</p> <p>We list below some of the sampling options implemented in the <code>sbi</code> package:</p> <ul> <li>MCMC<ul> <li>Custom implementation of slice sampling</li> <li>Hamiltonian Monte Carlo (HMC or NUTS) via pyro</li> <li>Hamiltonian Monte Carlo (HMC or NUTS) via PyMC</li> </ul> </li> <li>Rejection sampling</li> <li>Importance sampling</li> <li>Variational inference</li> </ul> <pre><code>posterior = inference.build_posterior(\n    density_estimator=density_estimator, sample_with=\"mcmc\"\n)\n</code></pre> <pre><code>/Users/bernardoveronese/miniconda3/envs/sbibench/lib/python3.10/site-packages/sbi/inference/posteriors/mcmc_posterior.py:114: UserWarning: The default value for thinning in MCMC sampling has been changed from 10 to 1. This might cause the results differ from the last benchmark.\n  thin = _process_thin_default(thin)\n</code></pre> <p>Generating samples with MCMC:</p> <pre><code>%%time\nsamples_from_nle = posterior.sample((num_samples,), x=fiducial_x)\n</code></pre> <pre><code>  0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n\n  0%|          | 0/1200 [00:00&lt;?, ?it/s]\n\n\nCPU times: user 1min 17s, sys: 884 ms, total: 1min 18s\nWall time: 1min 24s\n</code></pre> <pre><code>plot_corner(theta_labels, samples_from_nle, fiducial_theta.squeeze())\n</code></pre> <p></p>"},{"location":"tutorials/introduction/#neural_ratio_estimation_nre","title":"Neural Ratio Estimation (NRE)","text":"<p>As we have seen, the output of prior + simulator is the array of pairs \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i)\\) is drawn from the joint distribution</p> \\[     (\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i) \\sim p(\\boldsymbol{x}, \\boldsymbol{\\theta}) = p(\\boldsymbol{x} | \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) \\] <p>We now consider the shuffled pairs \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_j)\\), where \\(\\boldsymbol{x}_i\\) is the output of the forward-modeled input \\(\\boldsymbol{\\theta}_i, \\, i \\neq j\\). These pairs are sampled from the product distribution</p> \\[     (\\boldsymbol{x}_i, \\boldsymbol{\\theta}_j) \\sim p(\\boldsymbol{x}) p(\\boldsymbol{\\theta}) \\] <p>The idea of NRE is to train a classifier to learn the ratio</p> \\[     r(\\boldsymbol{x}, \\boldsymbol{\\theta}) \\equiv \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})p(\\boldsymbol{\\theta})} = \\frac{p(\\boldsymbol{x} | \\boldsymbol{\\theta})}{p(\\boldsymbol{x})},  \\] <p>which is equal to the likelihood-to-evidence ratio. The application of Bayes' theorem makes the connection between \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) and the Bayesian inverse problem:</p> \\[     r(\\boldsymbol{x}, \\boldsymbol{\\theta}) = \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})} = \\frac{p(\\boldsymbol{\\theta} | \\boldsymbol{x})}{p(\\boldsymbol{\\theta})}. \\] <p>In other words, \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) equals the posterior-to-prior ratio. Therefore, one can get samples from the posterior distribution of \\(\\boldsymbol{\\theta}\\) from the approximate knowledge of \\(r(\\boldsymbol{x}, \\boldsymbol{\\theta})\\) and prior samples from \\(\\boldsymbol{\\theta}\\).</p> <p>More specifically, the binary classifier \\(d_{\\boldsymbol{\\phi}} (\\boldsymbol{x}, \\boldsymbol{\\theta})\\) with learnable parameters \\(\\boldsymbol{\\phi}\\) is trained to distinguish the \\((\\boldsymbol{x}_i, \\boldsymbol{\\theta}_i)\\) pairs sampled from the joint distribution from their shuffled counterparts. We label pairs with a variable \\(y\\), such that \\(y=1\\) refers to joint pairs, and \\(y=0\\) to shuffled pairs. The classifier is trained to approximate</p> \\[\\begin{equation*} \\begin{split}     d_{\\boldsymbol{\\phi}} (\\boldsymbol{x}, \\boldsymbol{\\theta}) &amp;\\approx p(y=1 | \\boldsymbol{x}, \\boldsymbol{\\theta})\\\\     &amp;= \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 1) p(y = 1)}{p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 0) p(y = 0) + p(\\boldsymbol{x}, \\boldsymbol{\\theta} | y = 1) p(y = 1)}\\\\     &amp;= \\frac{p(\\boldsymbol{x}, \\boldsymbol{\\theta})}{p(\\boldsymbol{x})\\boldsymbol{\\theta} + p(\\boldsymbol{x}, \\boldsymbol{\\theta})}\\\\     &amp;= \\frac{r(\\boldsymbol{x}, \\boldsymbol{\\theta)}}{1 + r(\\boldsymbol{x}, \\boldsymbol{\\theta)}}, \\end{split} \\end{equation*}\\] <p>where we used \\(p(y=0)=p(y=1)=0.5\\).</p> <p>The classifier learns the parameters \\(\\boldsymbol{\\phi}\\) by minimizing the binary-cross entropy, defined as</p> \\[     L(d_{\\boldsymbol{\\phi}}) = - \\int d\\boldsymbol{\\theta} \\int d\\boldsymbol{x} p(\\boldsymbol{x}, \\boldsymbol{\\theta})\\log d_{\\boldsymbol{\\phi}}(\\boldsymbol{x}, \\boldsymbol{\\theta}) - p(\\boldsymbol{x})\\boldsymbol{\\theta}\\log(1-d_{\\boldsymbol{\\phi}}(\\boldsymbol{x}, \\boldsymbol{\\theta})) \\] <pre><code>from sbi.inference import SNRE\n\ninference = SNRE(prior=prior)\ninference.append_simulations(theta, x)\n</code></pre> <pre><code>&lt;sbi.inference.snre.snre_b.SNRE_B at 0x15bf88250&gt;\n</code></pre> <pre><code>%%time \ndensity_estimator = inference.train()\n</code></pre> <pre><code> Neural network successfully converged after 48 epochs.CPU times: user 9.79 s, sys: 302 ms, total: 10.1 s\nWall time: 6.18 s\n</code></pre> <pre><code>%%time \nposterior = inference.build_posterior(\n    density_estimator=density_estimator, sample_with=\"mcmc\"\n)\nsamples_from_nre = posterior.sample((num_samples,), x=fiducial_x)\n</code></pre> <pre><code>  0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n\n  0%|          | 0/1200 [00:00&lt;?, ?it/s]\n\n\nCPU times: user 35.5 s, sys: 670 ms, total: 36.2 s\nWall time: 47.7 s\n</code></pre> <pre><code>plot_corner(theta_labels, samples_from_nre, fiducial_theta.squeeze())\n</code></pre> <p></p>"},{"location":"tutorials/introduction/#analyzing_our_results","title":"Analyzing our results","text":"<p>For comparison, we draw samples from the true posterior:</p> <pre><code>samples_from_true_posterior = get_true_posterior_samples(num_samples, fiducial_x)\nplot_corner(theta_labels, samples_from_true_posterior, fiducial_theta.squeeze())\n</code></pre> <p></p> <p>We validate our results using the C2ST metric, where a classifier is trained to distinguish samples of the true posterior from samples of the estimated posterior and returns a score between 0.5 and 1. If the samples are indistinguishable, the classification performance should be random, and the returned score is 0.5. Higher scores indicate that the classifier is better able to learn to distinguish between the two sample populations.</p> <pre><code>from sbi.utils.metrics import c2st\n\nc2st_scores = dict(\n    zip(\n        (\"NPE\", \"NLE\", \"NRE\"),\n        (\n            c2st(samples, samples_from_true_posterior, seed=seed)\n            for samples in (samples_from_npe, samples_from_nle, samples_from_nre)\n        ),\n    )\n)\nprint(c2st_scores)\n</code></pre> <pre><code>{'NPE': tensor([0.6960]), 'NLE': tensor([0.6160]), 'NRE': tensor([0.6690])}\n</code></pre>"},{"location":"tutorials/introduction/#references","title":"References","text":"<p>[1]: Cranmer, Kyle, Johann Brehmer, and Gilles Louppe. \"The frontier of simulation-based inference.\" Proceedings of the National Academy of Sciences 117.48 (2020): 30055-30062.</p> <p>[2]: Tejero-Cantero, Alvaro, et al. \"SBI--A toolkit for simulation-based inference.\" arXiv preprint arXiv:2007.09114 (2020).</p> <p>[3]: Kobyzev, Ivan, Simon JD Prince, and Marcus A. Brubaker. \"Normalizing flows: An introduction and review of current methods.\" IEEE transactions on pattern analysis and machine intelligence 43.11 (2020): 3964-3979.</p> <p>[4]: Lueckmann, Jan-Matthis, et al. \"Benchmarking simulation-based inference.\" International conference on artificial intelligence and statistics. PMLR, 2021.</p>"}]}